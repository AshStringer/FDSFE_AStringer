{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshStringer/FDSFE_AStringer/blob/main/HW7/Kaggle_Customer_Profile_DBscan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9eyIY7SUwkGF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQpjMnUjwmEc",
        "outputId": "bf558d2a-a632-4f29-ba05-ea91e0057b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "McUWRkL5NC2a",
        "outputId": "27016415-1573-4295-ed38-3d0e56203482"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3HjlGcQw1-H",
        "outputId": "b216af3c-e941-4f73-e835-9c37e3bc2951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Kaggle\n"
          ]
        }
      ],
      "source": [
        "cd /content/gdrive/MyDrive/Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qku8VqbUyHKt",
        "outputId": "08023f9b-45c3-4033-d922-a2b53be55742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTZEx9r_yPRy",
        "outputId": "44ec058d-e966-4d79-d617-463c50863c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ],
      "source": [
        "ls kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePe5r7DN08s9"
      },
      "source": [
        "first make an account on kaggle and get your kaggle.json file from Account -> Settings. Then put it in a folder on your google drive called `kaggle`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wDcnNKEhyRkw"
      },
      "outputs": [],
      "source": [
        "!chmod 600 kaggle.json #only do it once!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ldlAjS8PyV15"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "envs = json.load(open(\"kaggle.json\", \"r\"))\n",
        "os.environ[\"KAGGLE_USERNAME\"] = envs['username']\n",
        "os.environ[\"KAGGLE_KEY\"] = envs['key']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0attFsN5wr-i"
      },
      "outputs": [],
      "source": [
        "import kaggle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCU7rauP1YSa"
      },
      "source": [
        "# get info on how to use kaggle datasets to find datasets by name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ9eBfMywyUT",
        "outputId": "ab803ca8-4abb-4296-9b30-09ec94e2ec25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: kaggle datasets [-h] {list,files,download,create,version,init,metadata,status} ...\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "\n",
            "commands:\n",
            "  {list,files,download,create,version,init,metadata,status}\n",
            "    list                List available datasets\n",
            "    files               List dataset files\n",
            "    download            Download dataset files\n",
            "    create              Create a new dataset\n",
            "    version             Create a new dataset version\n",
            "    init                Initialize metadata file for dataset creation\n",
            "    metadata            Download metadata about a dataset\n",
            "    status              Get the creation status for a dataset\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEjVQuQv1enJ"
      },
      "source": [
        "# find a file named customer personality analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_js0SXOD19mO",
        "outputId": "0689ebce-0e2d-40c5-8438-ff44e1508719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                      title                                  size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-------------------------------------------------------  ------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "imakash3011/customer-personality-analysis                Customer Personality Analysis          62KB  2021-08-22 18:15:05         160303       2556  0.9705882        \n",
            "blastchar/telco-customer-churn                           Telco Customer Churn                  172KB  2018-02-23 18:20:00         280190       2847  0.88235295       \n",
            "datascientistanna/customers-dataset                      Shop Customer Data                     23KB  2023-02-07 18:42:21          39206        534  1.0              \n",
            "vetrirah/customer                                        Customer Segmentation                 105KB  2020-08-28 11:19:39          18138        162  1.0              \n",
            "barun2104/telecom-churn                                  Customer Churn                         45KB  2020-03-23 16:30:13          14041        142  0.9411765        \n",
            "vjchoudhary7/customer-segmentation-tutorial-in-python    Mall Customer Segmentation Data         2KB  2018-08-11 07:23:02         194097       1721  0.88235295       \n",
            "iamsouravbanerjee/customer-shopping-trends-dataset       Customer Shopping Trends Dataset      146KB  2023-10-05 06:45:37          57047        768  1.0              \n",
            "sakshigoyal7/credit-card-customers                       Credit Card customers                 379KB  2020-11-19 07:38:44         112762       2262  1.0              \n",
            "abisheksudarshan/customer-segmentation                   Customer Segmentation                  99KB  2023-08-25 10:12:20           6881         72  1.0              \n",
            "abhinav89/telecom-customer                               Telecom customer                       14MB  2017-08-27 03:01:50          12880        205  0.7058824        \n",
            "radheshyamkollipara/bank-customer-churn                  Bank Customer Churn                   307KB  2023-04-28 16:32:01          18359        170  1.0              \n",
            "mahirahmzh/starbucks-customer-retention-malaysia-survey  Starbucks Customer Survey               5KB  2020-05-16 15:44:54          20822        210  0.9117647        \n",
            "kaushiksuresh147/customer-segmentation                   Customer Segmentation Classification  100KB  2023-09-12 21:41:36          15580        150  1.0              \n",
            "sjleshrac/airlines-customer-satisfaction                 Airlines Customer satisfaction          2MB  2020-03-19 15:33:25          18864        174  0.9411765        \n",
            "dev0914sharma/customer-clustering                        Customer Clustering                    26KB  2021-05-07 12:17:03          15243        118  0.7647059        \n",
            "thoughtvector/customer-support-on-twitter                Customer Support on Twitter           169MB  2017-12-03 23:44:27          35086        484  0.9117647        \n",
            "hanaksoy/customer-purchasing-behaviors                   Customer Purchasing Behaviors           1KB  2024-09-01 22:18:07          11966        102  1.0              \n",
            "muhammadshahidazeem/customer-churn-dataset               Customer Churn Dataset                  7MB  2023-06-14 11:16:49           9773         91  1.0              \n",
            "ihormuliar/starbucks-customer-data                       Starbucks Customer Data                 7MB  2021-03-31 08:14:17          10094         90  1.0              \n",
            "joebeachcapital/customer-segmentation                    Customer Segmentation                   2KB  2023-08-15 00:17:34           1339         37  1.0              \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!kaggle datasets list -s \"customer\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOMxGCZeRxfb",
        "outputId": "e2312c73-8dd8-4ab8-eb4d-f14b0ec08074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Kaggle\n"
          ]
        }
      ],
      "source": [
        "cd /content/gdrive/MyDrive/Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_M977mgRrTc",
        "outputId": "4e95ef2a-c76a-4941-c77b-84bdebb3f9ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘kaggledatasets’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir kaggledatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SYzFORjtR7MY"
      },
      "outputs": [],
      "source": [
        "!cd /content/gdrive/MyDrive/Kaggle/kaggledatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdePs5dX2XOO",
        "outputId": "e0236436-c673-42c4-82e3-9e9ceb303950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis\n",
            "License(s): CC0-1.0\n",
            "customer-personality-analysis.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d imakash3011/customer-personality-analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPinKYM42TyV"
      },
      "source": [
        "# unpack the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISnpAReB3hEO",
        "outputId": "cce74928-9f87-4201-956b-dbe861f02521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer-personality-analysis.zip  kaggledatasets  kaggle.json\tmarketing_campaign.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zwJr9L_JGgT",
        "outputId": "7507172a-d31c-4dbe-e1c9-07cfa1afd233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  customer-personality-analysis.zip\n",
            "replace marketing_campaign.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip customer-personality-analysis.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8m1mjL72Wju"
      },
      "source": [
        "# read in the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YeFiFcPJIY_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "customers = pd.read_csv(\"marketing_campaign.csv\", sep=\"\\t\")\n",
        "customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYrHmgO42aYQ"
      },
      "source": [
        "# remove all columns that do not contain numbers (or equivalently select all columns that do)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHwHDJ7VJMxD"
      },
      "outputs": [],
      "source": [
        "customers = customers.select_dtypes(include=\"number\")\n",
        "customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASBKArn9JbuM"
      },
      "outputs": [],
      "source": [
        "customers.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nunw8eg5KPgk"
      },
      "outputs": [],
      "source": [
        "column_length = {c:len(customers[c].unique()) for c in customers.columns}\n",
        "column_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XrbpV7e2iMK"
      },
      "source": [
        "# remove all columns that have less than 50 unique values (or select all those that have >50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxgtc5JFJ_Xb"
      },
      "outputs": [],
      "source": [
        "customers = customers[[c for c in customers.columns if column_length[c] > 50]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmY-LQPcVOTY"
      },
      "outputs": [],
      "source": [
        "customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXal-D_N2o5i"
      },
      "source": [
        "# remove the ID which should be a mute index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lax3NzTsJl_u"
      },
      "outputs": [],
      "source": [
        "customers.drop(\"ID\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybYr0r7ELIQt"
      },
      "outputs": [],
      "source": [
        "customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl92RIqY2uq9"
      },
      "source": [
        "# create a column that contains the age of the customer, instead of the birth year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjmXmp4ILJRn"
      },
      "outputs": [],
      "source": [
        "customers[\"Age\"] = 2024 - customers[\"Year_Birth\"]\n",
        "customers.drop(\"Year_Birth\", axis=1, inplace=True)\n",
        "customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmvE-p1n20jj"
      },
      "source": [
        "# scale the data so each feature is mean 0 and standard deviation 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISQObqXrLZL2"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t380KPUWTgZ"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaled_customers = scaler.fit_transform(customers)\n",
        "scaled_customers = pd.DataFrame(scaled_customers, columns=customers.columns)\n",
        "scaled_customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhJh57iVLdeg"
      },
      "outputs": [],
      "source": [
        "#check that each column is mean 0 stdev 1\n",
        "scaled_customers.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41uxeLEILmXr"
      },
      "source": [
        "# PLOT HISTOGRAMS OF ALL VARIABLES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIkQ7eIR3C5E"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "for column in scaled_customers.columns:\n",
        "    plt.figure(figsize=(8, 6))  # Adjust figure size as needed\n",
        "    plt.hist(scaled_customers[column], bins=30)  # Adjust number of bins as needed\n",
        "    plt.title(f'Histogram of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a histogram plot of all the variables in the data."
      ],
      "metadata": {
        "id": "711Bim83teS5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsK5Td2V3G5q"
      },
      "source": [
        "# write a caption for the scatter matrix below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJCI7BwvLtlI"
      },
      "outputs": [],
      "source": [
        "# prompt: plot a scatter matrix of the scaled dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "# Assuming 'scaled_customers' DataFrame is already created\n",
        "\n",
        "# Create a scatter matrix plot\n",
        "scatter_matrix(scaled_customers, alpha=0.2, figsize=(15, 15), diagonal='kde')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1d9v3S9kVbt"
      },
      "source": [
        "This scatter matrix is very interesting. Income plots look different than the others. Also, the plot is very linear."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HakhfWU03Ldw"
      },
      "source": [
        "# fix NaN by IMPUTING WITH k-NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fhm9yVOMEtw"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "scaled_customers_imputed = imputer.fit_transform(scaled_customers)\n",
        "\n",
        "scaled_customers_imputed = pd.DataFrame(scaled_customers_imputed, columns=scaled_customers.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw3OCjsuMSxD"
      },
      "outputs": [],
      "source": [
        "scaled_customers.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSHxKmuD3RCT"
      },
      "source": [
        "# CLUSTER THE DATA WITH DB SCAN, THEN SEE HOW MANY CLUSTERS THERE ARE AND HOW MANY OBJECTS IN EACH CLUSTER (your result may differe from mine!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPY_L8GZLRj5"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "\n",
        "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
        "clusters = dbscan.fit_predict(scaled_customers_imputed)\n",
        "\n",
        "\n",
        "unique_clusters, counts = np.unique(clusters, return_counts=True)\n",
        "\n",
        "\n",
        "print(\"Number of clusters:\", len(unique_clusters) - (1 if -1 in unique_clusters else 0))\n",
        "\n",
        "for cluster, count in zip(unique_clusters, counts):\n",
        "    print(f\"Cluster {cluster}: {count} objects\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose to use eps=0.3 so that I could get smaller clusters. So, that more noise points could be marked as outliers and to not miss any important clusters."
      ],
      "metadata": {
        "id": "OU9HjfBxvjDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a cluster plot of the data which is unique because you can see different groups which might look different than a normal plot."
      ],
      "metadata": {
        "id": "Pb1yOcPZt7bk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skE8MPrVgvzO"
      },
      "outputs": [],
      "source": [
        "# prompt: plot a box and whiskers plot of the distribution of scaled_customer features for each cluster\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'scaled_customers' DataFrame and 'clusters' are already created\n",
        "\n",
        "# Create a box and whiskers plot for each cluster\n",
        "for column in scaled_customers.columns:\n",
        "  if column != 'cluster':  # Exclude the cluster column itself\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    scaled_customers.boxplot(column=column, by='cluster')\n",
        "    plt.title(f'Boxplot of {column} by Cluster')\n",
        "    plt.suptitle('')  # Remove the default suptitle\n",
        "    plt.xlabel('Cluster')\n",
        "    plt.ylabel(column)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is also an interesting way to show the data by using box and whisker plots."
      ],
      "metadata": {
        "id": "s8auhRwHuKpF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AznWU4GtMneK"
      },
      "outputs": [],
      "source": [
        "# prompt: produce a tsne 2d projection of scaled_data and plot it colored by cluster\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Assuming 'scaled_customers' DataFrame with 'cluster' column is already created\n",
        "\n",
        "# Create a t-SNE object\n",
        "tsne = TSNE(n_components=2, random_state=42, early_exaggeration=15, perplexity=50)\n",
        "\n",
        "# Fit and transform the scaled data to reduce it to 2 dimensions\n",
        "tsne_results = tsne.fit_transform(scaled_customers.drop('cluster', axis=1))\n",
        "\n",
        "# Add the t-SNE results to the DataFrame\n",
        "scaled_customers['tsne_x'] = tsne_results[:, 0]\n",
        "scaled_customers['tsne_y'] = tsne_results[:, 1]\n",
        "\n",
        "# Plot the t-SNE projection, colored by cluster\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(scaled_customers['tsne_x'], scaled_customers['tsne_y'], c=scaled_customers['cluster'], cmap='viridis')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title('t-SNE Projection of Customer Data Colored by Cluster')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This just used colors to distinguish each cluster which is very helpful when looking at it."
      ],
      "metadata": {
        "id": "5P7rRUtFuQct"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}